# Class E: Data and AI

This section lists AI/ML and LLM technologies related to text/numeric data processing.
They can help teams to work more efficiently, improve the software quolity, and respond to issues more quickly and effectively.
For example, they can assist developers in writing code more quickly and accurately.
This can save time and increase productivity, allowing teams to deliver software more quickly and with higher quality.
Also, they can be used to automatically detect and classify incidents in software systems, and even suggest solutions or automatically resolve issues.
This can help teams to resolve incidents more quickly and with less manual effort.

## Data visualization

* matplotlib <https://matplotlib.org/>
  * seaborn <https://seaborn.pydata.org/>
* Vega <https://vega.github.io/vega/>
* Vega-Lite <https://vega.github.io/vega-lite/>
* D3 <https://d3js.org/>

## ML licecycle management

* MLFlow <https://mlflow.org/>
* KubeFlow <https://www.kubeflow.org/>

## Machine learning

* Common tools
  * Stochastic gradient descent <https://en.wikipedia.org/wiki/Stochastic_gradient_descent>
  * Dynamic programming <https://en.wikipedia.org/wiki/Dynamic_programming>
  * Sigmoid function <https://en.wikipedia.org/wiki/Sigmoid_function>
  * Softmax function <https://en.wikipedia.org/wiki/Softmax_function>
  * Early stopping <https://en.wikipedia.org/wiki/Early_stopping>
* Supervised learning <https://en.wikipedia.org/wiki/Supervised_learning>
  * Ensemble learning <https://en.wikipedia.org/wiki/Ensemble_learning>
  * Logistic regression <https://en.wikipedia.org/wiki/Logistic_regression>
  * Support vector machine <https://en.wikipedia.org/wiki/Support_vector_machine>
  * Random forest <https://en.wikipedia.org/wiki/Random_forest>
  * Artificial neural network <https://en.wikipedia.org/wiki/Artificial_neural_network>
  * ARIMA model <https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average>
* Unsupervised learning <https://en.wikipedia.org/wiki/Unsupervised_learning>
* Reinforcement learning <https://en.wikipedia.org/wiki/Reinforcement_learning>
  * Markov decision process <https://en.wikipedia.org/wiki/Markov_decision_process>
  * Multi-armed bandit <https://en.wikipedia.org/wiki/Multi-armed_bandit>
  * Value function <https://en.wikipedia.org/wiki/Value_function>

## Deep learning

* Deep Learning <https://en.wikipedia.org/wiki/Deep_learning>
  * Backpropagation <https://en.wikipedia.org/wiki/Backpropagation>
  * Autoencoder <https://en.wikipedia.org/wiki/Autoencoder>
  * Vanishing gradient problem <https://en.wikipedia.org/wiki/Vanishing_gradient_problem>
  * Rectifier <https://en.wikipedia.org/wiki/Rectifier_(neural_networks)>
  * Fine tuning <https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)>
  * Recurrent neural network <https://en.wikipedia.org/wiki/Recurrent_neural_network>
    * LSTM <https://en.wikipedia.org/wiki/Long_short-term_memory>

## ML tools

* scikit-learn <https://scikit-learn.org/stable>

## ML as a service

* Azure Machine Learning <https://azure.microsoft.com/en-us/products/machine-learning/>
* Amazon SageMaker <https://aws.amazon.com/sagemaker/>

## Deep learning frameworks

* TensorFlow <https://www.tensorflow.org/>
  * TFDS <https://www.tensorflow.org/datasets>
  * Keras <https://keras.io/>
* PyTorch <https://pytorch.org/>

## Programming language for AI

* Mojo <https://www.modular.com/mojo>

## Package management for computational science

* Anaconda distribution <http://anaconda.com/>

## Interactive computing

* JupyterLab / Jupiter Notebook <https://jupyter.org/>
* BeakerX <http://beakerx.com/>

## Typesetting system for scientific documents

* LaTeX <https://www.latex-project.org/>
  * TexLive <https://tug.org/texlive/>
* KaTeX <https://katex.org/>

## Statistics backgrounds

* Probability theory <https://en.wikipedia.org/wiki/Probability_theory>
* Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>
* Bayes' theorem <https://en.wikipedia.org/wiki/Bayes%27_theorem>
* Regression analysis <https://en.wikipedia.org/wiki/Regression_analysis>
* Confusion matrix <https://en.wikipedia.org/wiki/Confusion_matrix>
  * ROC curve <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>
* Statistical hypothesis testing <https://en.wikipedia.org/wiki/Statistical_hypothesis_testing>
* Confounding <https://en.wikipedia.org/wiki/Confounding>
* Experimental design <https://en.wikipedia.org/wiki/Design_of_experiments>
* Cross-validation <https://en.wikipedia.org/wiki/Cross-validation_(statistics)>

## Statistics tools

* Pandas <https://pandas.pydata.org/>
* NumPy <https://numpy.org/>
* SciPy <https://scipy.org/>
* R project <https://www.r-project.org/>
* RStudio <https://posit.co/download/rstudio-desktop/>
* JASP <https://jasp-stats.org/>

## NLP

* n-gram <https://en.wikipedia.org/wiki/N-gram>
* tf-idf (term frequencyâ€“inverse document frequency) <https://en.wikipedia.org/wiki/Tf%E2%80%93idf>
* Word2vec <https://en.wikipedia.org/wiki/Word2vec>
  * fastText <https://fasttext.cc/>
* GloVe <https://nlp.stanford.edu/projects/glove/>
* ULMFiT <https://arxiv.org/abs/1801.06146>
* ELMo <https://arxiv.org/abs/1802.05365>
* Transformer <https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)>

## Pretrained LLM

* BERT <https://arxiv.org/abs/1810.04805>
* GPT-4 <https://openai.com/research/gpt-4> <https://arxiv.org/abs/2303.08774>
* LLaMA <https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/>
* InstructGPT <https://arxiv.org/abs/2203.02155>
* Codex <https://arxiv.org/abs/2107.03374>

## Coding assistant

* GitHub Copilot <https://github.com/features/copilot/>
* Visual Studio IntelliCode <https://marketplace.visualstudio.com/items?itemName=VisualStudioExptTeam.vscodeintellicode>
* CodeGPT <https://www.codegpt.co/>
